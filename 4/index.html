<!DOCTYPE html>
<html lang="en-US">
    <head>
        <title> Project 4 Report</title>
        <link rel="stylesheet" href="pageStyle4.css" media="screen">
        <link rel="stylesheet" href="printStyle4.css" media="print">
    </head>
    <body style="width:100%;height:100%">
        <div class = "sideBar" id = "tableOfContents">
            <div class = "sideBarInner" id = "tableOfContentsInner">
                <h2>Jump to Section</h2>
                <a href="#Introduction"> Introduction</a> <br>
                <a href="#Shoot the Pictures">Shooting the Pictures</a><br>
                <a href="#Homography">Compute Homographies</a><br>
                <a href="#Rectification">Image Rectification</a><br>
                <a href="#Mosaics">Assemble Mosaics</a><br>
                <a href="#Part 2">Part 2</a><br>
                <a href="#Harris Points">Harris Points</a><br>
                <a href="#ANMS">ANMS</a><br>
                <a href="#Feature Descriptors">Feature Descriptors</a><br>
                <a href="#Feature Matching">Feature Matching</a><br>
                
            </div>
        </div>
        <div class = "mainPortion" id = "mainSection">
            <h1 style="margin-left: 25%; font-size: 2vw">Project 4: Image Warping and Mosaic-ing</h1>
            <div class = "mainText" id = "mainSectionInner">
                <p style="text-align: center; margin-right:11%">By: Andi Liu</p>
                <br>
                <h2 id = "Introduction">1. Introduction</h2>
                <p>In this project we will be exploring different aspects of image warping with the ultimate goal of image mosaic-ing. For each mosaic, we will take at least two <br>
                photographs and register, projective warp, resample, and composite them into mosaics. We will also learn to compute and use homographies to warp images.</p>
                <p>Writing the code: We will be re-using some of the basic functions written in the previous projects, for importing, displaying, and saving images. These will be<br>
                stored and imported in my utils.py file. We will also be using some functions from project 3 that we used for defining point correspondences between images. These functions will<br>
                also be defined in the utils.py file.</p>
                
                <h2 id="Shoot the Pictures">Shooting the Pictures</h2>
                <p>To begin with our project, we will need to procure our images. For each mosaic, the set of images need to be related by projective (perspective) transforms.<br>
                We will obtain these by fixing the center of projection and rotating our camera.
                </p>
                <p>Below is the first set of images that we will be using for this project</p>
                <img src="media/mosaic1source.png"><br>
                <p>We will be warping the second image to be in the same plane as the first. In order to do this we first need to label point correspondences between the images.<br>
                We will use the tool we wrote in project 3 for this, and obtain the point correspondences depicted below:</p>
                <img src="media/mosaic1simplecorrespondences.png"><br>
                <h2 id="Homography">Compute The Homographies</h2>
                <p>Since the images are related by a projective transform (a homography), we will need to figure out what the homography is. We reason out the mathematics needed<br>
                in order to compute the homography. (taken from the jupyter notebook I wrote my code on)</p>
                <img src="media/reasoning1.jpg"><br>
                <img src="media/reasoning2.jpg"><br>
                <p>Now that we've written a function for computing homographies, we can write a function using our inverse warping process from project 3, that warps one image<br>
                into the plane of another through a computed homography. Putting our second image through this function we obtain the following warped image, displayed next to the original.</p>
                <img src="media/warpsidebyside1.png"><br>
                <p>Here is the warped image next to the other image in the mosaic:</p>
                <img src="media/mosaic1afterwarp.png"><br>
                <p>We can see that the angle of the warped image seems slightly misaligned from the other. This is because we used only four points of correspondence and the<br>
                homography is determined by eight values, meaning our points uniquely determine a homography. We can improve the alignment by labelling more points of correspondence<br>
                and using least squares to compute a homography that most closely aligns with all of them. After modifying our homography function to handle more than 4 points and<br>
                recomputing the warp we get a much better result</p>
                <img src="media/mosaic1morecorrespondences.png"><br>
                <img src="media/warpsidebyside1new.png"><br>
                <img src="media/mosaic1afterwarpnew.png"><br>
                <p>Now the building in the warped image looks very closely aligned with the building in the first image.</p>
                <h2 id="Rectification">Image Rectification</h2>
                <p>Now that we've confirmed out function can warp images using homographies, we'll put it to the test by warping some other images. To demonstrate the capabilities<br>
                we will choose some features of images that we know to be flat, and warp them so that we appear to be looking at it. Below we show the feature used to compute the homography<br>
                as well as the rectified image.</p>
                <img src="media/rect1points.png" style="height:15%;width:15%"><img src="media/rectification1.png" style="height:15%;width:15%"><br>
                <img src="media/rect2points.png" style="height:15%;width:15%"><img src="media/rectification12.png" style="height:15%;width:15%"><br>
                <img src="media/rect3points.png" style="height:15%;width:15%"><img src="media/rectification21.png" style="height:15%;width:15%"><br>
                <h2 id="Mosaics">Assembling Mosaics</h2>
                <p>Now that we are able to warp images into other image's planes, we can put warped images together to create mosaics. After writing a function that overlays one image<br>
                onto the other and averages their intersection, we can create some simple mosaics. Below are some mosaics along with their original images:</p>
                <img src="media/mosaic1source.png"><br>
                <img src="media/mosaic1.png"><br>
                <img src="media/mosaic2sidebyside.png"><br>
                <img src="media/mosaic2.png"><br>
                <img src="media/mosaic3sidebyside.png"><br>
                <img src="media/mosaic3.png"><br>

                <h1 id="Part 2">Part 2: Feature Matching for AutoStitching</h1>
                <h2>Introduction</h2>
                <p>For the next part of the project we will be implementing feature detection and extraction for the purposes of matching. In order to do this we will implement the <br>
                process described in the paper  “Multi-Image Matching using Multi-Scale Oriented Patches” by Brown et al. We will use an image with particularly evident features, which
                will make it evident whether or not our code is working. The chosen image is a bunch of differently shaped rubix cubes.</p>
                <img src="media/Rubiks-Cube-Collection.jfif"><br>
                <h2 id="Harris Points">Finding Harris Points</h2>
                <p>The first thing we will implement from the paper is the Harris Corner detector. In order to find Harris corners, we first need to take the x and y spacial derivatives<br>
                Then we join them together to form a column gradient vector, and take the outer product of the gradient with itself. This matrix is then used to calculate the Harris values<br>
                througout the image. We do this by looking at the ratio of the determinants of this matrix to the trace of the matrix. If the H value is large, this tells us that the image<br>
                is changing significantly in both x and y directions at a certain point, meaning that it is highly distinguishable (a Harris corner). Below we depict all the Harris points<br>
                our algorithm detects on our image, both with and without the image in the background.</p>
                <img src="media/harrispointsNoBack.png" style="height:50%;width:50%">
                <img src="media/harrispointsWithBack.png" style="height:50%;width:50%"><br>
                <h2 id="ANMS">Adaptive Non-maximal Supression (ANMS)</h2>
                <p>Since our Harris point detector clearly picked up too many points, we want to suppress non-maximum points where there is dense packing, while keeping points that are detected<br>
                in sparse areas. For this we will use Adaptive Non-Maximal Suppression, a technique described in the paper wherein points are "suppressed" if there is a more "edge-like" point <br>
                nearby, leaving only the most edge-like points in densely populated areas without filtering out points in sparse areas. After implementing this algorithm, we observe the top 50,<br>
                150, and 300 points chosen by Adaptive Non-Maximal Suppression. </p>
                <img src="media/ANMS50.png"><br>
                <img src="media/ANMS150.png"><br>
                <img src="media/ANMS300.png"><br>
                <h2 id="Feature Descriptors">Feature Descriptors</h2>
                <p>Now that we have the locations of distinct features, we still need a way to label the features. In order to do this, Brown et al. use gradient-aligned patches that are local<br>
                to the image. We will do the same. The first step is to find the gradient and the gradient-orthogonal at each point of interest. When we do this, we convolve the image with a 2D<br>
                Gaussian in order to smooth out the gradient surface, so that there is less variability with feature location. Below we show the 50 ANMS points along with the computed gradients<br>
                and orthogonals.</p>
                <img src="media/GradOrth50.png"><br>
                <p>After computing the gradient and orthogonal, we will extract a chunk of the local image large enough to rotate and align with the gradient, and then Gaussian blur by a factor of 5<br>
                and finally sample the 9 by 9 patch of pixels around our location of interest. We show some original extracted image patches below, followed by 50 examples of image patches before and<br>
                after gradient-alignment, gaussian blurring, and then sampling.</p>
                <img src="media/GradOrthLocal.png"><br>
                <img src="media/descriptors.png"><br>
                <img src="media/descriptorsFinal.png"><br>
                <h2 id="Feature Matching">Feature Matching</h2>
                <p>Now that we are able to extract features out of our images, all that remains to do is to match them between images. For this purpose we will use the two images from our first mosaic.<br>
                After running our images through the feature extractor we get the following for the first image:</p>
                <img src="media/img1Harris.jpg">
                <img src="media/img1ANMS.jpg">
                <img src="media/img1descriptors.jpg">
                <img src="media/img1descriptorsBlurred.jpg">
                <p>And for the second image we get the following features:</p>
                <img src="media/img2Harris.jpg">
                <img src="media/img2ANMS.jpg">
                <img src="media/img2descriptors.jpg">
                <img src="media/img2descriptorsBlurred.jpg">
                <p>Now, for the matching algorithm we will simply use normalized cross-correlation, however as the paper suggests we will use the Lowe method, which is to only classify two features as<br>
                a match if the correlation between the second closest match is a certain threshold below the correlation betweeen the image and the closest match. We see that this gives us very good results.<br>
                Depicted below are a few pairs of matches out of 700 points selected out of the ANMS algorithm.</p>
                <img src="media/match0.png">
                <img src="media/match1.png">
                <img src="media/match2.png">
                <img src="media/match3.png">
                <img src="media/match4.png">
                <img src="media/match5.png">
                <img src="media/match6.png">
                <img src="media/match7.png">
                <img src="media/match8.png">
                <img src="media/match9.png">
                <img src="media/match10.png">
                <img src="media/match11.png">
                <p>We can see that the results we get are quite good.</p>





                
            </div>
        </div>
    </body>


</html>
